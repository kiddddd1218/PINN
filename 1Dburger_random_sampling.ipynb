{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using device: {device}')\n",
    "# lam = 0.4  \n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, out_features)\n",
    "        self.fc2 = nn.Linear(out_features, out_features)\n",
    "        self.activation = torch.sin\n",
    "        \n",
    "        if in_features != out_features:\n",
    "            self.shortcut = nn.Linear(in_features, out_features)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.activation(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out += identity\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        # self.hidden_layer1 = ResidualBlock(1, 24)\n",
    "        # self.hidden_layer2 = ResidualBlock(24, 17)\n",
    "        # self.hidden_layer3 = ResidualBlock(17, 10)\n",
    "        # self.hidden_layer4 = ResidualBlock(10, 3)\n",
    "        # self.hidden_layer5= ResidualBlock(3, 3)\n",
    "\n",
    "        self.hidden_layer1 = nn.Linear(1, 20)\n",
    "        self.hidden_layer2 = nn.Linear(20, 20)\n",
    "        self.hidden_layer3 = nn.Linear(20, 20)\n",
    "        self.hidden_layer4 = nn.Linear(20, 20)\n",
    "\n",
    "        # self.hidden_layer1 = nn.Linear(1, 24)\n",
    "        # self.hidden_layer2 = nn.Linear(24, 17)\n",
    "        # self.hidden_layer3 = nn.Linear(17, 10)\n",
    "        # self.hidden_layer4 = nn.Linear(10, 3)\n",
    "        # self.hidden_layer5 = nn.Linear(3, 3)\n",
    "        self.output_layer = nn.Linear(20, 1)\n",
    "        self.learned = False \n",
    "        self.log_lam = torch.tensor(0.0)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = torch.tanh(self.hidden_layer1(y))\n",
    "        y = torch.tanh(self.hidden_layer2(y))\n",
    "        y = torch.tanh(self.hidden_layer3(y))\n",
    "        y = torch.tanh(self.hidden_layer4(y))\n",
    "        # y = torch.tanh(self.hidden_layer5(y))\n",
    "        y = self.output_layer(y)\n",
    "        return y\n",
    "    \n",
    "    def U(self, y):\n",
    "        return (self(y) - self(-y)) / 2\n",
    "\n",
    "    def get_lam(self, y):\n",
    "        if self.learned:\n",
    "            U = self.U(y)\n",
    "            U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "            U_yy = torch.autograd.grad(U_y, y, grad_outputs=torch.ones_like(U_y), create_graph=True)[0]\n",
    "            return torch.mean(torch.divide(y*U_yy , -(1 + U_y) * U_y - (U + y)*U_yy))\n",
    "        return .4\n",
    "    \n",
    "def f(y,U,U_y,lam):\n",
    "    return -lam * U + ((1 + lam) * y + U) * U_y\n",
    "\n",
    "def compute_derivative(f, y, model, lam, orders,finite=False):\n",
    "    y.requires_grad = True\n",
    "    U = model.U(y)\n",
    "    U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "    lam = model.get_lam(y)\n",
    "    f_val = f(y, U, U_y, lam)\n",
    "    h = y[1] - y[0]\n",
    "    res = []\n",
    "    if not finite:\n",
    "        for _ in range(int(orders.max())):\n",
    "            f_val = torch.autograd.grad(f_val, y, grad_outputs=torch.ones_like(f_val), create_graph=True)[0]\n",
    "            if _ + 1 in orders:\n",
    "                res.append(f_val)\n",
    "    else:\n",
    "        for _ in range(int(orders.max())):\n",
    "            f_val = (y[1:] - y[:-1]) / h\n",
    "            if _ + 1 in orders:\n",
    "                res.append(f_val)\n",
    "    return res\n",
    "\n",
    "def Loss(model, y, collocation_points):\n",
    "    y.requires_grad = True\n",
    "    U = model.U(y)\n",
    "    U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "    lam = model.get_lam(y)\n",
    "\n",
    "    # Equation loss\n",
    "    f_val = f(y, U, U_y,lam)\n",
    "\n",
    "    # Smooth loss 3rd and fifth derivative\n",
    "    derivatives = compute_derivative(f,collocation_points,model,lam,np.array([3.0]),True)\n",
    "    f_yyy = derivatives[0]\n",
    "    # f_yyyyy = derivatives[1]\n",
    " \n",
    "\n",
    "    # Condition loss U(-2) = 1\n",
    "    g = model.U(torch.tensor([-2.0], dtype=y.dtype, device=y.device)) - 1\n",
    "    \n",
    "    equation_loss = torch.mean(f_val**2)\n",
    "    condition_loss = torch.mean(g**2)\n",
    "\n",
    "    total_loss = equation_loss + condition_loss + 1e-3*torch.mean(f_yyy**2) #+ 1e-5*torch.mean(f_yyyyy**2)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 22.626935958862305\n",
      "epoch 1, loss 0.021237915381789207\n",
      "epoch 2, loss 0.010468811728060246\n",
      "epoch 3, loss 0.009003899991512299\n",
      "epoch 4, loss 0.008861695416271687\n",
      "epoch 5, loss 0.012052849866449833\n",
      "epoch 6, loss 0.00833094958215952\n",
      "epoch 7, loss 0.02335018664598465\n",
      "epoch 8, loss 0.03339057415723801\n",
      "epoch 9, loss 0.008581708185374737\n",
      "epoch 10, loss 0.01116197369992733\n",
      "epoch 11, loss 0.008121078833937645\n",
      "epoch 12, loss 0.013945475220680237\n",
      "epoch 13, loss 0.2813381552696228\n",
      "epoch 14, loss 0.049136821180582047\n",
      "epoch 15, loss 0.01099590864032507\n",
      "epoch 16, loss 0.008149244822561741\n",
      "epoch 17, loss 0.016965333372354507\n",
      "epoch 18, loss 0.009786972776055336\n",
      "epoch 19, loss 0.015034589916467667\n",
      "epoch 20, loss 0.011710010468959808\n",
      "epoch 21, loss 0.008820496499538422\n",
      "epoch 22, loss 0.008811186999082565\n",
      "epoch 23, loss 0.1055724024772644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollocation_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollocation_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollocation_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcollocation_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:329\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    327\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:878\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    875\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    876\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 878\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\Will\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:810\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    808\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 810\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model \n",
    "\n",
    "model = PINN().to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 128 \n",
    "y_data = torch.linspace(-2,2,10000).view(-1, 1).to(device)\n",
    "\n",
    "Ns = 1000\n",
    "collocation_points = torch.FloatTensor(Ns).uniform_(-1, 1).view(-1, 1).to(device)\n",
    "collocation_points = (collocation_points - collocation_points.mean()) / collocation_points.std()\n",
    "\n",
    "# Create DataLoader for y_data and collocation_points\n",
    "y_dataset = TensorDataset(y_data)\n",
    "collocation_dataset = TensorDataset(collocation_points)\n",
    "y_loader = DataLoader(y_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "collocation_loader = DataLoader(collocation_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "def closure(y_batch, collocation_batch):\n",
    "    optimizer.zero_grad()  \n",
    "    loss = Loss(model, y_batch, collocation_batch)  \n",
    "    loss.backward()  \n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for y_batch, collocation_batch in zip(y_loader, collocation_loader):\n",
    "        y_batch = y_batch[0].to(device)\n",
    "        collocation_batch = collocation_batch[0].to(device)\n",
    "        optimizer.step(lambda: closure(y_batch, collocation_batch)) #\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        y_batch = next(iter(y_loader))[0].to(device)\n",
    "        collocation_batch = next(iter(collocation_loader))[0].to(device)\n",
    "        loss = Loss(model, y_batch, collocation_batch)\n",
    "        print(f'epoch {epoch}, loss {loss.item()}')\n",
    "        if loss.item() <= 1e-8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda learned in the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learned = True\n",
    "for epoch in range(num_epochs):\n",
    "    for y_batch, collocation_batch in zip(y_loader, collocation_loader):\n",
    "        y_batch = y_batch[0].to(device)\n",
    "        collocation_batch = collocation_batch[0].to(device)\n",
    "        optimizer.step(lambda: closure(y_batch, collocation_batch))\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        y_batch = next(iter(y_loader))[0].to(device)\n",
    "        collocation_batch = next(iter(collocation_loader))[0].to(device)\n",
    "        loss = Loss(model, y_batch, collocation_batch)\n",
    "        print(f'epoch {epoch}, loss {loss.item()}')\n",
    "        if loss.item() <= 1e-8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = 2*torch.sin(torch.linspace(-np.pi/2, np.pi/2, 100)).view(-1, 1).to(device)\n",
    "y_test.requires_grad = True\n",
    "# Get model predictions and detach to move to CPU\n",
    "U_pred = model.U(y_test)\n",
    "U_pred_y = torch.autograd.grad(U_pred, y_test, grad_outputs=torch.ones_like(U_pred), create_graph=True)[0]\n",
    "U_pred_yy = torch.autograd.grad(U_pred_y, y_test, grad_outputs=torch.ones_like(U_pred_y), create_graph=True)[0]\n",
    "U_pred_yyy = torch.autograd.grad(U_pred_yy, y_test, grad_outputs=torch.ones_like(U_pred_yy), create_graph=True)[0]\n",
    "U_pred_yyyy = torch.autograd.grad(U_pred_yyy, y_test, grad_outputs=torch.ones_like(U_pred_yyy), create_graph=True)[0]\n",
    "U_pred_yyyyy = torch.autograd.grad(U_pred_yyyy, y_test, grad_outputs=torch.ones_like(U_pred_yyyy), create_graph=True)[0]\n",
    "\n",
    "lam = model.get_lam(y_test).detach().cpu().numpy()\n",
    "print(lam)\n",
    "residual = f(y_test,U_pred,U_pred_y,lam)\n",
    "print(torch.sqrt(torch.mean(residual**2)))\n",
    "U_pred = U_pred.detach().cpu().numpy()\n",
    "# Generate exact solution using implicit formula\n",
    "U_positive = np.linspace(0, 1, 100)\n",
    "y_true = np.array([U_positive + U_positive**(1 + 1/lam), -U_positive - U_positive**(1 + 1/lam)]).flatten()\n",
    "order = y_true.argsort()\n",
    "U_sorted = np.array([-U_positive, U_positive]).flatten()[order]\n",
    "\n",
    "y_sorted = y_true[order]\n",
    "\n",
    "# Convert test data to numpy\n",
    "y_test_np = y_test.detach().cpu().numpy()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot the PINN Prediction vs Exact Solution\n",
    "ax1.plot(y_test_np, U_pred, '.-', label='PINN Prediction', color='#1f77b4', markersize=5)\n",
    "ax1.plot(y_sorted, U_sorted, label='Exact Solution', color='#ff7f0e', linestyle='--', linewidth=2)\n",
    "ax1.set_title('Comparison of PINN Prediction and Exact Solution')\n",
    "ax1.set_xlabel('y')\n",
    "ax1.set_ylabel('U')\n",
    "ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the third derivative\n",
    "ax2.plot(y_test_np, U_pred_yyy.detach().cpu().numpy(), '.-', label='Third Derivative of U', color='#2ca02c', markersize=5)\n",
    "ax2.set_title('Third Derivative of U')\n",
    "ax2.set_xlabel('y')\n",
    "ax2.set_ylabel('d^3U/dy^3')\n",
    "ax2.grid(True, which='both', linestyle='--', linewidth=0.51)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
