{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlbfgs\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using device: {device}')\n",
    "res_scale = .1\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(1, 24).double()\n",
    "        self.hidden_layer2 = nn.Linear(24, 24).double()\n",
    "        self.hidden_layer3 = nn.Linear(1, 13).double()\n",
    "        self.hidden_layer4 = nn.Linear(24, 13).double()\n",
    "\n",
    "        self.hidden_layer5 = nn.Linear(13, 13).double()\n",
    "        self.hidden_layer6 = nn.Linear(13, 13).double()\n",
    "        self.hidden_layer7 = nn.Linear(13, 7).double()\n",
    "        self.hidden_layer8 = nn.Linear(13, 7).double()\n",
    "\n",
    "        self.hidden_layer9 = nn.Linear(7, 7).double()\n",
    "        self.hidden_layer10 = nn.Linear(7, 7).double()\n",
    "        self.hidden_layer11 = nn.Linear(7, 1).double()\n",
    "        self.hidden_layer12 = nn.Linear(7, 1).double()\n",
    "    \n",
    "        \n",
    "    def forward(self, y):\n",
    "        res = torch.sin(self.hidden_layer1(y))\n",
    "        res = torch.tanh(self.hidden_layer2(res))\n",
    "        y = self.hidden_layer3(y) + res_scale * self.hidden_layer4(res)\n",
    "\n",
    "        res = torch.sin(self.hidden_layer5(y))\n",
    "        res = torch.tanh(self.hidden_layer6(res))\n",
    "        y = self.hidden_layer7(y) + res_scale * self.hidden_layer8(res)\n",
    "\n",
    "        res = torch.sin(self.hidden_layer9(y))\n",
    "        res = torch.tanh(self.hidden_layer10(res))\n",
    "        y = self.hidden_layer11(y) + res_scale * self.hidden_layer12(res)\n",
    "        return y\n",
    "    \n",
    "    def U(self, y):\n",
    "        return (self(y) - self(-y)) / 2\n",
    "\n",
    "    def get_lam(self):\n",
    "        y = torch.linspace(-2,2,10,dtype=torch.float64).view(-1,1).to(device)\n",
    "        y.requires_grad = True\n",
    "        U = self.U(y)\n",
    "        U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "        U_yy = torch.autograd.grad(U_y, y, grad_outputs=torch.ones_like(U_y), create_graph=True)[0]\n",
    "        return torch.mean(torch.divide(-(1 + U_y) * U_y - (U + y) * U_yy, y * U_yy))\n",
    "        # return torch.mean(torch.divide((y + U) * U_y,U - y * U_y))\n",
    "    def get_fixed_lam(self):\n",
    "        return .4\n",
    "    \n",
    "def f(y,U,U_y,lam):\n",
    "    return -lam * U + ((1 + lam) * y + U) * U_y\n",
    "\n",
    "def compute_derivative(f, y, model, lam, orders,finite=False):\n",
    "    y.requires_grad = True\n",
    "    U = model.U(y)\n",
    "    U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "    lam = model.get_lam()\n",
    "    f_val = f(y, U, U_y, lam)\n",
    "    h = y[1] - y[0]\n",
    "    res = []\n",
    "    if not finite:\n",
    "        for _ in range(int(orders.max())):\n",
    "            f_val = torch.autograd.grad(f_val, y, grad_outputs=torch.ones_like(f_val), create_graph=True)[0]\n",
    "            if _ + 1 in orders:\n",
    "                res.append(f_val)\n",
    "    else:\n",
    "        for _ in range(int(orders.max())):\n",
    "            f_val = (y[1:] - y[:-1]) / h\n",
    "            if _ + 1 in orders:\n",
    "                res.append(f_val)\n",
    "    return res\n",
    "\n",
    "# @torch.compile\n",
    "def Loss(model, y, collocation_points,mode,step):\n",
    "    y.requires_grad = True\n",
    "    U = model.U(y)\n",
    "    U_y = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "    # U_yy = torch.autograd.grad(U, y, grad_outputs=torch.ones_like(U), create_graph=True,retain_graph=)[0]\n",
    "    if mode == 'fixed':\n",
    "        lam = model.get_fixed_lam()\n",
    "    if mode == 'learned':\n",
    "        lam = model.get_lam()\n",
    "\n",
    "\n",
    "    # Equation loss\n",
    "    f_val = f(y, U, U_y,lam)\n",
    "\n",
    "    # Smooth loss 3rd and fifth derivative\n",
    "    derivatives = compute_derivative(f,collocation_points,model,lam, orders=np.array([3.0]),finite=True)\n",
    "    f_yyy = derivatives[0]\n",
    "    #f_yyyyy = derivatives[1]\n",
    " \n",
    "\n",
    "    # Condition loss U(-2) = 1\n",
    "    g = model.U(torch.tensor([-2.0], dtype=y.dtype, device=y.device)) - 1\n",
    "    \n",
    "    equation_loss = torch.mean(f_val**2)\n",
    "    condition_loss = torch.mean(g**2)\n",
    "\n",
    "   # experiment_loss = torch.exp(torch.tensor(data=[-0.5],dtype=torch.float64) * step + torch.tensor(data=[1],dtype=torch.float64)) * torch.mean(U_y**2)\n",
    "    total_loss = equation_loss + condition_loss + 1e-3*torch.mean(f_yyy**2) #+ 1e-10*torch.mean(f_yyyyy**2) \n",
    "    return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SLIM] initialize SlimQN optimizer:\n",
      "-------------------------------------\n",
      "\tInitial learning rate: 0.05\n",
      "\tMomentum for update: 0.9\n",
      "\tWeight decay: 0.0\n",
      "\tDamping factor: 0.2\n",
      "\tMomentum for param: 0.9\n",
      "\tMomentum for grad: 0.99\n",
      "\tHistory vector size: 100\n",
      "\tBase Hessian update frequency: 100\n",
      "\tGradient clipping: 0.005\n",
      "\tNumber of threads: 16\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>\n",
      "\n",
      "AssertionError: Traceback (most recent call last):\n",
      "can only test a child process  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "\n",
      "    AssertionErrorself._shutdown_workers(): \n",
      "can only test a child process  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      ":   File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "can only test a child process    \n",
      "self._shutdown_workers()\n",
      "Exception ignored in:   File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>    \n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      "AssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>can only test a child process\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "Exception ignored in:   File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>    \n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "AssertionError    : can only test a child processif w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>AssertionError\n",
      ": Traceback (most recent call last):\n",
      "can only test a child process  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>    \n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "AssertionError    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a8f437640>: \n",
      "can only test a child processTraceback (most recent call last):\n",
      "\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kido/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "Traceback (most recent call last):\n",
      "Assertion failed: ok (src/mailbox.cpp:72)\n",
      "No such file or directory (src/epoll.cpp:118)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 481982) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 481982) is killed by signal: Aborted. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y_batch, collocation_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y_loader, collocation_loader):\n\u001b[1;32m     59\u001b[0m         y_batch \u001b[38;5;241m=\u001b[39m y_batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m         collocation_batch \u001b[38;5;241m=\u001b[39m collocation_batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 481982) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Initialize model \n",
    "import slim\n",
    "model = PINN().to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "# optimizer = mlbfgs.LBFGSOptimizer(\n",
    "#     model_parameters=model.parameters(),\n",
    "#     lr = .1,              \n",
    "#     momentum=0.9,       \n",
    "#     weight_decay=0.0,    \n",
    "#     rho_min=0.0001,\n",
    "#     mm_p=0.9,\n",
    "#     mm_g=0.99,\n",
    "#     update_freq=100,      \n",
    "#     hist_sz=100,\n",
    "#     decay_period=10,\n",
    "#     damping=0.2,         \n",
    "#     kl_clip=0.005         \n",
    "# )\n",
    "optimizer = slim.SlimQN(\n",
    "    model_parameters=model.parameters(),\n",
    "    lr = .05,              \n",
    "    momentum=0.9,       \n",
    "    weight_decay=0.0,    \n",
    "    rho_min=0.0001,\n",
    "    mm_p=0.9,\n",
    "    mm_g=0.99,\n",
    "    update_freq=100,      \n",
    "    hist_sz=100,\n",
    "    decay_period=10,\n",
    "    damping=0.2,         \n",
    "    kl_clip=0.005         \n",
    ")\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1000\n",
    "batch_size = 8912 // 2\n",
    "y_data = torch.linspace(-2,2,10000,dtype=torch.float64).view(-1, 1).to(device)\n",
    "\n",
    "Ns = 1000\n",
    "collocation_points = torch.FloatTensor(Ns).uniform_(-1, 1).view(-1, 1).double().to(device)\n",
    "collocation_points = (collocation_points - collocation_points.mean()) / collocation_points.std()\n",
    "\n",
    "# Create DataLoader for y_data and collocation_points\n",
    "y_dataset = TensorDataset(y_data)\n",
    "collocation_dataset = TensorDataset(collocation_points)\n",
    "y_loader = DataLoader(y_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "collocation_loader = DataLoader(collocation_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "def closure(y_batch, collocation_batch,step):\n",
    "    optimizer.zero_grad()  \n",
    "    loss = Loss(model, y_batch, collocation_batch,'fixed',step)  \n",
    "    loss.backward()  \n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for y_batch, collocation_batch in zip(y_loader, collocation_loader):\n",
    "        y_batch = y_batch[0].to(device)\n",
    "        collocation_batch = collocation_batch[0].to(device)\n",
    "        optimizer.step() #lambda: closure(y_batch, collocation_batch,epoch)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        y_batch = next(iter(y_loader))[0].to(device)\n",
    "        collocation_batch = next(iter(collocation_loader))[0].to(device)\n",
    "        loss = Loss(model, y_batch, collocation_batch,'fixed',epoch)\n",
    "        print(f'epoch {epoch}, loss {loss.item()}')\n",
    "        if loss.item() <= 1e-8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda learned in the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(y_batch, collocation_batch):\n",
    "    optimizer.zero_grad()  \n",
    "    loss = Loss(model, y_batch, collocation_batch,'learned')  \n",
    "    loss.backward()  \n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for y_batch, collocation_batch in zip(y_loader, collocation_loader):\n",
    "        y_batch = y_batch[0].to(device)\n",
    "        collocation_batch = collocation_batch[0].to(device)\n",
    "        optimizer.step(lambda: closure(y_batch, collocation_batch)) #\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        y_batch = next(iter(y_loader))[0].to(device)\n",
    "        collocation_batch = next(iter(collocation_loader))[0].to(device)\n",
    "        loss = Loss(model, y_batch, collocation_batch,'learned')\n",
    "        print(f'epoch {epoch}, loss {loss.item()}')\n",
    "        if loss.item() <= 1e-8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = 2*torch.sin(torch.linspace(-np.pi/2, np.pi/2, 100)).view(-1, 1).to(device)\n",
    "y_test.requires_grad = True\n",
    "# Get model predictions and detach to move to CPU\n",
    "U_pred = model.U(y_test)\n",
    "U_pred_y = torch.autograd.grad(U_pred, y_test, grad_outputs=torch.ones_like(U_pred), create_graph=True)[0]\n",
    "U_pred_yy = torch.autograd.grad(U_pred_y, y_test, grad_outputs=torch.ones_like(U_pred_y), create_graph=True)[0]\n",
    "U_pred_yyy = torch.autograd.grad(U_pred_yy, y_test, grad_outputs=torch.ones_like(U_pred_yy), create_graph=True)[0]\n",
    "U_pred_yyyy = torch.autograd.grad(U_pred_yyy, y_test, grad_outputs=torch.ones_like(U_pred_yyy), create_graph=True)[0]\n",
    "U_pred_yyyyy = torch.autograd.grad(U_pred_yyyy, y_test, grad_outputs=torch.ones_like(U_pred_yyyy), create_graph=True)[0]\n",
    "\n",
    "lam = model.get_lam(y_test).detach().cpu().numpy()\n",
    "print(lam)\n",
    "residual = f(y_test,U_pred,U_pred_y,lam)\n",
    "print(torch.sqrt(torch.mean(residual**2)))\n",
    "U_pred = U_pred.detach().cpu().numpy()\n",
    "# Generate exact solution using implicit formula\n",
    "U_positive = np.linspace(0, 1, 100)\n",
    "y_true = np.array([U_positive + U_positive**(1 + 1/lam), -U_positive - U_positive**(1 + 1/lam)]).flatten()\n",
    "order = y_true.argsort()\n",
    "U_sorted = np.array([-U_positive, U_positive]).flatten()[order]\n",
    "\n",
    "y_sorted = y_true[order]\n",
    "\n",
    "# Convert test data to numpy\n",
    "y_test_np = y_test.detach().cpu().numpy()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot the PINN Prediction vs Exact Solution\n",
    "ax1.plot(y_test_np, U_pred, '.-', label='PINN Prediction', color='#1f77b4', markersize=5)\n",
    "ax1.plot(y_sorted, U_sorted, label='Exact Solution', color='#ff7f0e', linestyle='--', linewidth=2)\n",
    "ax1.set_title('Comparison of PINN Prediction and Exact Solution')\n",
    "ax1.set_xlabel('y')\n",
    "ax1.set_ylabel('U')\n",
    "ax1.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the third derivative\n",
    "ax2.plot(y_test_np, U_pred_yyy.detach().cpu().numpy(), '.-', label='Third Derivative of U', color='#2ca02c', markersize=5)\n",
    "ax2.set_title('Third Derivative of U')\n",
    "ax2.set_xlabel('y')\n",
    "ax2.set_ylabel('d^3U/dy^3')\n",
    "ax2.grid(True, which='both', linestyle='--', linewidth=0.51)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
